{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sqrt(x):\n",
    "    y = np.sqrt(x)\n",
    "    return y\n",
    "\n",
    "def Cbrt(x):\n",
    "    y = np.cbrt(x)\n",
    "    return y\n",
    "\n",
    "def Log(x):\n",
    "    y = np.log(1 + x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv('../Data/population.csv')\n",
    "roads = pd.read_csv('../Data/roads_network.csv')\n",
    "df = pd.read_csv('../Data/train.csv')\n",
    "test_set = pd.read_csv('../Data/test.csv')\n",
    "\n",
    "#DATA CLEANUP\n",
    "df = df.drop(columns=[\n",
    "    #'Local_Authority_(District)',\n",
    "    #'Local_Authority_(Highway)',\n",
    "    #'1st_Road_Number',\n",
    "    '2nd_Road_Number',\n",
    "    'country',\n",
    "    'Accident_ID'\n",
    "    ])\n",
    "\n",
    "\n",
    "#POPULATION CLEANUP\n",
    "pop = pop.rename(columns={\n",
    "    'postcode': 'postcode_merge',\n",
    "    'Variable: All usual residents; measures: Value': 'Population',\n",
    "    'Variable: Males; measures: Value': 'Male_Count',\n",
    "    'Variable: Females; measures: Value': 'Female_Count',\n",
    "    'Variable: Lives in a household; measures: Value': 'Lives_in_Household',\n",
    "    'Variable: Lives in a communal establishment; measures: Value': 'Lives_in_Communal',\n",
    "    'Variable: Schoolchild or full-time student aged 4 and over at their non term-time address; measures: Value': 'Children_Count',\n",
    "    'Variable: Area (Hectares); measures: Value': 'Area',\n",
    "    'Variable: Density (number of persons per hectare); measures: Value': 'Pop_Density'\n",
    "}).drop(columns=['Rural Urban'])\n",
    "\n",
    "pop['Male_Perc'] = pop['Male_Count'] / pop['Population']\n",
    "pop['Female_Perc'] = pop['Female_Count'] / pop['Population']\n",
    "pop['Lives_in_Household_Perc'] = pop['Lives_in_Household'] / pop['Population']\n",
    "pop['Lives_in_Communal_Perc'] = pop['Lives_in_Communal'] / pop['Population']\n",
    "pop['Children_Perc'] = pop['Children_Count'] / pop['Population']\n",
    "\n",
    "\n",
    "df['postcode_merge'] = df['postcode'].str.replace(' ', '')\n",
    "df['postcode_merge'] = df['postcode_merge'].str[:-2]\n",
    "pop['postcode_merge'] = pop['postcode_merge'].str.replace(' ', '')\n",
    "df = pd.merge(df, pop, on='postcode_merge', how='left')\n",
    "df = df.drop(columns=['postcode_merge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    'Day_of_Week',\n",
    "    '1st_Road_Number',\n",
    "    '1st_Road_Class',\n",
    "    'Road_Type',\n",
    "    '2nd_Road_Class',\n",
    "    'Pedestrian_Crossing-Human_Control',\n",
    "    'Pedestrian_Crossing-Physical_Facilities',\n",
    "    'Light_Conditions',\n",
    "    'Weather_Conditions',\n",
    "    'Road_Surface_Conditions',\n",
    "    'Special_Conditions_at_Site',\n",
    "    'Carriageway_Hazards',\n",
    "    'state',\n",
    "    'Local_Authority_(District)',\n",
    "    'Local_Authority_(Highway)',\n",
    "    'Month'\n",
    "]\n",
    "\n",
    "num_cols = [\n",
    "    'Police_Force',\n",
    "    'Number_of_Vehicles',\n",
    "    'Speed_limit',\n",
    "    'Lives_in_Household_Perc',\n",
    "    'Lives_in_Communal_Perc',\n",
    "    'Hour'\n",
    "]\n",
    "\n",
    "bin_cols = [\n",
    "    'Urban_or_Rural_Area',\n",
    "    'Did_Police_Officer_Attend_Scene_of_Accident'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sqrt_cols = [\n",
    "    'Children_Count',\n",
    "    'Male_Count',\n",
    "    'Female_Count',\n",
    "    'Population',\n",
    "    'Lives_in_Household'\n",
    "]\n",
    "\n",
    "\n",
    "cbrt_cols = [\n",
    "    'Children_Perc',\n",
    "    'Male_Perc',\n",
    "    'Female_Perc'\n",
    "]\n",
    "\n",
    "log_cols = [\n",
    "    'Lives_in_Communal',\n",
    "    'Area',\n",
    "    'Pop_Density',\n",
    "]\n",
    "\n",
    "\n",
    "for x in df.columns:\n",
    "    if x not in cat_cols + num_cols + sqrt_cols + cbrt_cols + log_cols:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TIME CONVERSIONS\n",
    "def GetHour(x):\n",
    "    y = x.hour\n",
    "    z = x.minute / 60\n",
    "    return y + z\n",
    "\n",
    "def GetMonth(x):\n",
    "    y = x.month\n",
    "    return y\n",
    "\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df['Hour'] = df['Time'].apply(GetHour)\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Month'] = df['Date'].apply(GetMonth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BINARY CONVERSION\n",
    "urban_rural_dict = {\n",
    "    1: 0,\n",
    "    2: 1\n",
    "}\n",
    "\n",
    "police_dict = {\n",
    "    'Yes': 1,\n",
    "    'No': 0\n",
    "}\n",
    "\n",
    "df['Urban_or_Rural_Area'] = df['Urban_or_Rural_Area'].map(urban_rural_dict)\n",
    "df['Did_Police_Officer_Attend_Scene_of_Accident'] = df['Did_Police_Officer_Attend_Scene_of_Accident'].map(police_dict)\n",
    "\n",
    "df = df.drop(columns=['Date', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('postcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEPARATE TARGET AND FEATURES\n",
    "\n",
    "X = df.drop(columns=['Number_of_Casualties'])\n",
    "y = df[['Number_of_Casualties']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('sqrt', FunctionTransformer(Sqrt)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cbrt_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('cbrt', FunctionTransformer(Cbrt)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "log_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('log', FunctionTransformer(Log)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer([\n",
    "    ('sqrt', sqrt_pipeline, sqrt_cols),\n",
    "    ('cbrt', cbrt_pipeline, cbrt_cols),\n",
    "    ('log', log_pipeline, log_cols),\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "], remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trans = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(ct):\n",
    "\n",
    "    output_features = []\n",
    "\n",
    "    for name, pipe, features in ct.transformers_:\n",
    "        for i in pipe:\n",
    "            trans_features = []\n",
    "            if hasattr(i,'categories_'):\n",
    "                trans_features.extend(i.get_feature_names(features))\n",
    "            else:\n",
    "                trans_features = features\n",
    "        output_features.extend(trans_features)\n",
    "\n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN DATA PROCESSING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sqrt(x):\n",
    "    y = np.sqrt(x)\n",
    "    return y\n",
    "\n",
    "\n",
    "def Cbrt(x):\n",
    "    y = np.cbrt(x)\n",
    "    return y\n",
    "\n",
    "\n",
    "def Log(x):\n",
    "    y = np.log(1 + x)\n",
    "    return y\n",
    "\n",
    "def GetHour(x):\n",
    "    y = x.hour\n",
    "    z = x.minute / 60\n",
    "    return y + z\n",
    "\n",
    "def GetMonth(x):\n",
    "    y = x.month\n",
    "    return y\n",
    "\n",
    "def get_feature_names(ct):\n",
    "    output_features = []\n",
    "    for name, pipe, features in ct.transformers_:\n",
    "        for i in pipe:\n",
    "            trans_features = []\n",
    "            if hasattr(i,'categories_'):\n",
    "                trans_features.extend(i.get_feature_names(features))\n",
    "            else:\n",
    "                trans_features = features\n",
    "        output_features.extend(trans_features)\n",
    "    return output_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def DataProcessing(train, test, pop):\n",
    "    #DATA CLEANUP\n",
    "    \n",
    "    drop_cols = [\n",
    "        #'Local_Authority_(District)',\n",
    "        #'Local_Authority_(Highway)',\n",
    "        #'1st_Road_Number',\n",
    "        '2nd_Road_Number',\n",
    "        'country',\n",
    "        'Accident_ID'\n",
    "        ]\n",
    "    \n",
    "    train = train.drop(columns=drop_cols)\n",
    "    test = test.drop(columns=drop_cols)\n",
    "\n",
    "\n",
    "    #POPULATION CLEANUP\n",
    "    pop = pop.rename(columns={\n",
    "        'postcode': 'postcode_merge',\n",
    "        'Variable: All usual residents; measures: Value': 'Population',\n",
    "        'Variable: Males; measures: Value': 'Male_Count',\n",
    "        'Variable: Females; measures: Value': 'Female_Count',\n",
    "        'Variable: Lives in a household; measures: Value': 'Lives_in_Household',\n",
    "        'Variable: Lives in a communal establishment; measures: Value': 'Lives_in_Communal',\n",
    "        'Variable: Schoolchild or full-time student aged 4 and over at their non term-time address; measures: Value': 'Children_Count',\n",
    "        'Variable: Area (Hectares); measures: Value': 'Area',\n",
    "        'Variable: Density (number of persons per hectare); measures: Value': 'Pop_Density'\n",
    "    }).drop(columns=['Rural Urban'])\n",
    "\n",
    "    pop['Male_Perc'] = pop['Male_Count'] / pop['Population']\n",
    "    pop['Female_Perc'] = pop['Female_Count'] / pop['Population']\n",
    "    pop['Lives_in_Household_Perc'] = pop['Lives_in_Household'] / pop['Population']\n",
    "    pop['Lives_in_Communal_Perc'] = pop['Lives_in_Communal'] / pop['Population']\n",
    "    pop['Children_Perc'] = pop['Children_Count'] / pop['Population']\n",
    "\n",
    "    #Train Merge\n",
    "    train['postcode_merge'] = train['postcode'].str.replace(' ', '')\n",
    "    train['postcode_merge'] = train['postcode_merge'].str[:-2]\n",
    "    pop['postcode_merge'] = pop['postcode_merge'].str.replace(' ', '')\n",
    "    train = pd.merge(train, pop, on='postcode_merge', how='left')\n",
    "    train = train.drop(columns=['postcode_merge'])\n",
    "    \n",
    "    #Test Merge\n",
    "    test['postcode_merge'] = test['postcode'].str.replace(' ', '')\n",
    "    test['postcode_merge'] = test['postcode_merge'].str[:-2]\n",
    "    pop['postcode_merge'] = pop['postcode_merge'].str.replace(' ', '')\n",
    "    test = pd.merge(test, pop, on='postcode_merge', how='left')\n",
    "    test = test.drop(columns=['postcode_merge'])\n",
    "    \n",
    "    cat_cols = [\n",
    "    'Day_of_Week',\n",
    "    '1st_Road_Number',\n",
    "    '1st_Road_Class',\n",
    "    'Road_Type',\n",
    "    '2nd_Road_Class',\n",
    "    'Pedestrian_Crossing-Human_Control',\n",
    "    'Pedestrian_Crossing-Physical_Facilities',\n",
    "    'Light_Conditions',\n",
    "    'Weather_Conditions',\n",
    "    'Road_Surface_Conditions',\n",
    "    'Special_Conditions_at_Site',\n",
    "    'Carriageway_Hazards',\n",
    "    'state',\n",
    "    'Local_Authority_(District)',\n",
    "    'Local_Authority_(Highway)',\n",
    "    'Month'\n",
    "    ]\n",
    "\n",
    "    num_cols = [\n",
    "        'Police_Force',\n",
    "        'Number_of_Vehicles',\n",
    "        'Speed_limit',\n",
    "        'Lives_in_Household_Perc',\n",
    "        'Lives_in_Communal_Perc',\n",
    "        'Hour'\n",
    "    ]\n",
    "\n",
    "    bin_cols = [\n",
    "        'Urban_or_Rural_Area',\n",
    "        'Did_Police_Officer_Attend_Scene_of_Accident'\n",
    "    ]\n",
    "\n",
    "    sqrt_cols = [\n",
    "        'Children_Count',\n",
    "        'Male_Count',\n",
    "        'Female_Count',\n",
    "        'Population',\n",
    "        'Lives_in_Household'\n",
    "    ]\n",
    "\n",
    "    cbrt_cols = [\n",
    "        'Children_Perc',\n",
    "        'Male_Perc',\n",
    "        'Female_Perc'\n",
    "    ]\n",
    "\n",
    "    log_cols = [\n",
    "        'Lives_in_Communal',\n",
    "        'Area',\n",
    "        'Pop_Density',\n",
    "    ]\n",
    "    \n",
    "    #Train Times\n",
    "    train['Time'] = pd.to_datetime(train['Time'])\n",
    "    train['Hour'] = train['Time'].apply(GetHour)\n",
    "\n",
    "    train['Date'] = pd.to_datetime(train['Date'])\n",
    "    train['Month'] = train['Date'].apply(GetMonth)\n",
    "    \n",
    "    \n",
    "    #Test Times\n",
    "    test['Time'] = pd.to_datetime(test['Time'])\n",
    "    test['Hour'] = test['Time'].apply(GetHour)\n",
    "\n",
    "    test['Date'] = pd.to_datetime(test['Date'])\n",
    "    test['Month'] = test['Date'].apply(GetMonth)\n",
    "    \n",
    "    #BINARY CONVERSION\n",
    "    urban_rural_dict = {\n",
    "        1: 0,\n",
    "        2: 1\n",
    "    }\n",
    "\n",
    "    police_dict = {\n",
    "        'Yes': 1,\n",
    "        'No': 0\n",
    "    }\n",
    "\n",
    "    train['Urban_or_Rural_Area'] = train['Urban_or_Rural_Area'].map(urban_rural_dict)\n",
    "    train['Did_Police_Officer_Attend_Scene_of_Accident'] = train['Did_Police_Officer_Attend_Scene_of_Accident'].map(police_dict)\n",
    "    \n",
    "    test['Urban_or_Rural_Area'] = test['Urban_or_Rural_Area'].map(urban_rural_dict)\n",
    "    test['Did_Police_Officer_Attend_Scene_of_Accident'] = test['Did_Police_Officer_Attend_Scene_of_Accident'].map(police_dict)\n",
    "\n",
    "    train = train.drop(columns=['Date', 'Time'])\n",
    "    test = test.drop(columns=['Date', 'Time'])\n",
    "    \n",
    "    train = train.set_index('postcode')\n",
    "    test = test.set_index('postcode')\n",
    "    \n",
    "    #SEPARATE TARGET AND FEATURES\n",
    "\n",
    "    X = train.drop(columns=['Number_of_Casualties'])\n",
    "    y = train[['Number_of_Casualties']]\n",
    "    \n",
    "    test_X = test.drop(columns=['Number_of_Casualties'])\n",
    "    \n",
    "\n",
    "    #PIPELINES\n",
    "    sqrt_pipeline = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='mean')),\n",
    "        ('sqrt', FunctionTransformer(Sqrt)),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    cbrt_pipeline = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='mean')),\n",
    "        ('cbrt', FunctionTransformer(Cbrt)),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    log_pipeline = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='mean')),\n",
    "        ('log', FunctionTransformer(Log)),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse=False, handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    ct = ColumnTransformer([\n",
    "    ('sqrt', sqrt_pipeline, sqrt_cols),\n",
    "    ('cbrt', cbrt_pipeline, cbrt_cols),\n",
    "    ('log', log_pipeline, log_cols),\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "    ], remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    X_trans = ct.fit_transform(X)\n",
    "    test_X = ct.transform(test_X)\n",
    "    y = y.to_numpy()\n",
    "    \n",
    "    return X_trans, y, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv('../Data/population.csv')\n",
    "roads = pd.read_csv('../Data/roads_network.csv')\n",
    "train = pd.read_csv('../Data/train.csv')\n",
    "test = pd.read_csv('../Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikea\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:170: UserWarning: Found unknown categories in columns [1, 13] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X, y, test_X = DataProcessing(train, test, pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.89172257,  0.24740525,  0.3765139 , ...,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.9761584 , -0.42684112, -0.306282  , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.47604706,  0.26404886,  0.41769921, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.84761331,  0.12541279,  0.16646817, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.32481087,  0.29014612,  0.40089719, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.38752924, -1.48343996, -1.49709067, ...,  1.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [4],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1416088 , -0.20989967, -0.14333436, ...,  0.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.39388693,  0.8082397 ,  0.93358443, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.14421713,  0.21086709,  0.27277988, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.60727123,  1.25014734,  1.02493948, ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [-1.32111368, -0.21329268, -0.26419135, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.36647216,  1.26284251,  0.91058527, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
